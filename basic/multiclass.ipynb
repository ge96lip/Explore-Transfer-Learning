{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4RDObXCJ1Dk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HisWZDtOJ5cI"
      },
      "outputs": [],
      "source": [
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faaCycj0J6_H"
      },
      "outputs": [],
      "source": [
        "# Transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(), # Data Augmentation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYEaWqzeKAAh"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "train_dataset = OxfordIIITPet(root='./data', split='trainval', target_types='category', download=True, transform=train_transform)\n",
        "test_dataset = OxfordIIITPet(root='./data', split='test', target_types='category', download=True, transform=test_transform)\n",
        "\n",
        "num_classes = 37\n",
        "\n",
        "# Data split\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=32)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TTpTNQybFqW"
      },
      "outputs": [],
      "source": [
        "def load_model():\n",
        "    # Load pretrained model and replace final layer\n",
        "    model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Freeze all layers except final classifier\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.fc.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex9N4yHXZzF8"
      },
      "outputs": [],
      "source": [
        "def train(model, criterion, optimizer, n_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Record time\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    print(f\"Time taken: {total_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwW1zbGnaZJH"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, eval_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in eval_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGF9bTMKfNbY"
      },
      "source": [
        "### Baseline: Fine-tune only classification layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPQRjwvpZYf5"
      },
      "outputs": [],
      "source": [
        "model = load_model()\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0003)\n",
        "\n",
        "# Start training\n",
        "print(f\"Fine-tuning only fully connected layer...\")\n",
        "n_epochs = 10\n",
        "train(model, criterion, optimizer, n_epochs)\n",
        "evaluate(model, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puBQ5c0dhILz"
      },
      "source": [
        "### Strategy 1: Fine-tune last l layers together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X9Oinqkzp1P"
      },
      "outputs": [],
      "source": [
        "for n in range(5):\n",
        "\n",
        "    model = load_model()\n",
        "\n",
        "    # Get trainable layers\n",
        "    blocks = [getattr(model, layer_name) for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']]\n",
        "\n",
        "    # Unfreeze n last blocks\n",
        "    if n > 0:\n",
        "        for l in blocks[-n:]:\n",
        "            for param in l.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0003)\n",
        "\n",
        "    # Training loop\n",
        "    print(f\"Partially fine-tuning last {n} layers...\")\n",
        "    n_epochs = 10\n",
        "\n",
        "    train(model, criterion, optimizer, n_epochs)\n",
        "    evaluate(model, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV-wCPaEhS3j"
      },
      "source": [
        "### Strategy 2: Gradually unfreeze layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvLcy2UfrALS"
      },
      "outputs": [],
      "source": [
        "model = load_model()\n",
        "\n",
        "# Get trainable layers\n",
        "blocks = [getattr(model, layer_name) for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']]\n",
        "\n",
        "# Define number of epochs and steps\n",
        "n_epochs = 5\n",
        "n_steps = 2\n",
        "total_epochs = n_steps * n_epochs\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"Starting gradual unfreezing...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Training loop\n",
        "t = 0\n",
        "for step in range(n_steps):\n",
        "\n",
        "    # Loss and optimizer\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0003)\n",
        "\n",
        "    train(model, criterion, optimizer, n_epochs)\n",
        "    evaluate(model, val_loader)\n",
        "\n",
        "    # Unfreeze all layers in the current block\n",
        "    if step < len(blocks):\n",
        "        block = blocks[-(step + 1)]\n",
        "        for l in block:\n",
        "            for param in l.parameters():\n",
        "                param.requires_grad = True\n",
        "        print(f\"Unfroze layers in residual block {-(step + 1)}\")\n",
        "\n",
        "\n",
        "# Record time\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Overall time taken: {total_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9rOcTEkhXGn"
      },
      "source": [
        "### Tuning: Maximize performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWviiEwpL6I2"
      },
      "outputs": [],
      "source": [
        "# Load pretrained model\n",
        "model = load_model()\n",
        "\n",
        "# Include batch norm params\n",
        "for m in model.modules():\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        for param in m.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "# Get trainable layers\n",
        "blocks = [getattr(model, layer_name) for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']]\n",
        "\n",
        "# Define number of epochs and steps\n",
        "n_epochs = 5\n",
        "n_steps = 5\n",
        "total_epochs = n_steps * n_epochs\n",
        "lr = 3e-3\n",
        "lam = 1e-3\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"Starting gradual unfreezing...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Training loop\n",
        "t = 0\n",
        "for step in range(n_steps):\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=lam)\n",
        "\n",
        "    # Train and evaluate\n",
        "    train(model, criterion, optimizer, n_epochs)\n",
        "    evaluate(model, val_loader)\n",
        "\n",
        "    # Decay lr and lambda\n",
        "    lr *= 0.1\n",
        "    lam *= 0.1\n",
        "\n",
        "    # Unfreeze all layers in the current block\n",
        "    if step < len(blocks):\n",
        "        block = blocks[-(step + 1)]\n",
        "        for l in block:\n",
        "            for param in l.parameters():\n",
        "                param.requires_grad = True\n",
        "        print(f\"Unfroze layers in residual block {-(step + 1)}\")\n",
        "\n",
        "# Record time\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Time taken: {total_time:.2f} seconds\")\n",
        "\n",
        "# Measure test performance\n",
        "evaluate(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}