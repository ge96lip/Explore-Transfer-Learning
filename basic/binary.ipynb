{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "QlECk6Gwukqr"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "bxHOjw3Au-OI"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Dataset Path\n",
        "data_dir = \"/content/data/oxford-iiit-pet/images\""
      ],
      "metadata": {
        "id": "VGVrLI_XA2O7"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "EjgV84rK9mBR"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define breed lists\n",
        "cat_breeds = [\n",
        "    'Abyssinian', 'Bengal', 'Birman', 'Bombay', 'British_Shorthair',\n",
        "    'Egyptian_Mau', 'Maine_Coon', 'Persian', 'Ragdoll', 'Russian_Blue',\n",
        "    'Siamese', 'Sphynx'\n",
        "]\n",
        "\n",
        "dog_breeds = [\n",
        "    'American_Bulldog', 'American_Pit_Bull_Terrier', 'Basset_Hound', 'Beagle',\n",
        "    'Boxer', 'Chihuahua', 'English_Cocker_Spaniel', 'English_Setter', 'German_Shorthaired',\n",
        "    'Great_Pyrenees', 'Havanese', 'Japanese_Chin', 'Keeshond', 'Leonberger', 'Miniature_Pinscher',\n",
        "    'Newfoundland', 'Pomeranian', 'Pug', 'Saint_Bernard', 'Samoyed', 'Scottish_Terrier',\n",
        "    'Shiba_Inu', 'Staffordshire_Bull_Terrier', 'Wheaten_Terrier', 'Yorkshire_Terrier'\n",
        "]"
      ],
      "metadata": {
        "id": "mbcxqqbDAfXI"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Dataset class\n",
        "class CustomPetDataset(Dataset):\n",
        "    def __init__(self, image_folder, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "        self.image_paths = glob.glob(os.path.join(image_folder, \"*.jpg\"))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        class_name = \"_\".join(os.path.basename(img_path).split(\"_\")[:-1]).lower()\n",
        "        cat_breeds_lower = [name.lower() for name in cat_breeds]\n",
        "        dog_breeds_lower = [name.lower() for name in dog_breeds]\n",
        "\n",
        "        if class_name in cat_breeds_lower:\n",
        "            binary_label = 0  # Cat\n",
        "        elif class_name in dog_breeds_lower:\n",
        "            binary_label = 1  # Dog\n",
        "        else:\n",
        "            print(f\"âš  Warning: Unknown breed found in filename {img_path}, skipping...\")\n",
        "            return None\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, binary_label\n"
      ],
      "metadata": {
        "id": "uXoUnKXBAlcY"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Datasets and Split\n",
        "trainval_dataset = CustomPetDataset(data_dir, transform=transform)\n",
        "\n",
        "# Get all valid labels first\n",
        "all_labels = []\n",
        "valid_indices = []\n",
        "for idx in range(len(trainval_dataset)):\n",
        "    sample = trainval_dataset[idx]\n",
        "    if sample is not None:\n",
        "        _, label = sample\n",
        "        all_labels.append(label)\n",
        "        valid_indices.append(idx)\n",
        "\n",
        "# Create train/val split\n",
        "train_idx, val_idx = train_test_split(\n",
        "    valid_indices,\n",
        "    test_size=0.2,\n",
        "    stratify=[all_labels[i] for i in range(len(all_labels))],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Create the final datasets\n",
        "train_dataset = torch.utils.data.Subset(trainval_dataset, train_idx)\n",
        "val_dataset = torch.utils.data.Subset(trainval_dataset, val_idx)\n",
        "test_dataset = CustomPetDataset(data_dir, transform=transform)"
      ],
      "metadata": {
        "id": "G2Vz_J8yBJSI"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Data Loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "tPRnNAjeBXuy"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print dataset sizes\n",
        "print(f\"Training size: {len(train_dataset)}\")\n",
        "print(f\"Validation size: {len(val_dataset)}\")\n",
        "print(f\"Test size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC2TQKD7BZrh",
        "outputId": "e103db48-c99d-4b98-bdba-d0fac6def656"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 5912\n",
            "Validation size: 1478\n",
            "Test size: 7390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained ResNet18\n",
        "model = torchvision.models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypxKa5p8vyJB",
        "outputId": "9466b633-26c8-4b9a-a5a1-16e6ce5b2152"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace final layer\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 1)  # Binary output\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "i9ROxqcTvzRY"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)"
      ],
      "metadata": {
        "id": "gXdjoPGLv-WP"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "n_epochs = 5\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mwgPNlrwGPU",
        "outputId": "ef777bff-927b-4184-a237-ed6e8f0756d6"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.0966\n",
            "Epoch [2/10], Loss: 0.0261\n",
            "Epoch [3/10], Loss: 0.0308\n",
            "Epoch [4/10], Loss: 0.0234\n",
            "Epoch [5/10], Loss: 0.0292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        predicted = (torch.sigmoid(outputs) > 0.5).squeeze().long()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlcFVq0RwN9o",
        "outputId": "bf3d16de-4104-4292-8361-5a54cdf9ca39"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Broq85gZxekC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
